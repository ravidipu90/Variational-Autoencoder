{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import torchvision as tv\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "from pytorch_msssim import SSIM\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt \n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.name = 'vae_kl_100'\n",
    "        self.dataset_name = 'mimic'\n",
    "        self.dataroot ='../DATASET/images'\n",
    "        \n",
    "        self.save_path = './checkpoint/' + self.name\n",
    "        self.model_path = self.save_path + '/models'\n",
    "        self.decode_path = self.save_path + '/decoded_results'\n",
    "        self.val_path = self.save_path + '/val_results'\n",
    "        self.test_path = self.save_path + '/test_results'\n",
    "        \n",
    "        self.num_threads = 8\n",
    "        self.shuffle_dataset=True\n",
    "        self.random_seed=24\n",
    "\n",
    "\n",
    "        self.lr = 0.00003     \n",
    "        \n",
    "        self.serial_batches = False\n",
    "        self.phase='train'\n",
    "        \n",
    "        self.train_batch_size = 6\n",
    "        self.val_batch_size = 6\n",
    "        self.test_batch_size = 1\n",
    "        self.max_epochs = 500\n",
    "        self.save_every = 1     #epoch\n",
    "        self.plot_every = 1     # epoch to save decoded images\n",
    "\n",
    "        os.makedirs(self.save_path, exist_ok=True)\n",
    "        os.makedirs(self.model_path, exist_ok=True)\n",
    "        os.makedirs(self.decode_path, exist_ok=True)\n",
    "        os.makedirs(self.val_path, exist_ok=True)\n",
    "        os.makedirs(self.test_path, exist_ok=True)\n",
    "opt = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize([0.546, 0.265, 0.406],\n",
    "\n",
    "transform={'train':transforms.Compose([transforms.Resize(256),\n",
    "                               transforms.CenterCrop(224),\n",
    "                               transforms.Grayscale(num_output_channels=1),\n",
    "                               transforms.RandomHorizontalFlip(),\n",
    "                               transforms.Lambda\n",
    "                                (lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "                               transforms.Lambda\n",
    "                                (lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
    "                             ]),\n",
    "            'val':transforms.Compose([transforms.Resize(256),\n",
    "                               transforms.CenterCrop(224),\n",
    "                               transforms.Grayscale(num_output_channels=1),\n",
    "                               transforms.Lambda\n",
    "                                 (lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "                               transforms.Lambda\n",
    "                                 (lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
    "                               transforms.ToTensor(),\n",
    "                             ])\n",
    "          }\n",
    "                                      \n",
    "class Data(data.Dataset):\n",
    "    def __init__(self,transform=None,phase=None):\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "        \n",
    "        train_file   = \"../DATASET/full_chex/train.csv\"\n",
    "        val_file   = \"../DATASET/full_chex/val.csv\"\n",
    "        test_file   = \"../DATASET/full_chex/test.csv\"\n",
    "        train_df = pd.read_csv(train_file)\n",
    "        val_df   = pd.read_csv(val_file)\n",
    "        test_df  = pd.read_csv(test_file)\n",
    "        \n",
    "        self.train_labels=train_df.set_index('id')['Labels'].to_dict()\n",
    "        self.val_labels=val_df.set_index('id')['Labels'].to_dict()\n",
    "        self.test_labels=test_df.set_index('id')['Labels'].to_dict()\n",
    "        \n",
    "        self.train_images= list(self.train_labels.keys()) \n",
    "        self.val_images= list(self.val_labels.keys())\n",
    "        self.test_images= list(self.test_labels.keys())\n",
    "        \n",
    "                \n",
    "    def __len__(self):\n",
    "        if self.phase == 'train':\n",
    "            return len(self.train_images)\n",
    "        if self.phase == 'val':\n",
    "            return len(self.val_images)\n",
    "        if self.phase == 'test':\n",
    "            return len(self.test_images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.phase == 'train':\n",
    "            file = self.train_images[index]\n",
    "            path = os.path.join(opt.dataroot,file)\n",
    "            image = Image.open(path)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                image = self.transform['train'](image)\n",
    "                \n",
    "            for key in self.train_labels.keys():\n",
    "                if file in key:\n",
    "                    label= self.train_labels[key]\n",
    "                    break\n",
    "        \n",
    "            label = torch.LongTensor([label])\n",
    "    #         label = torch.FloatTensor([label])\n",
    "            return {'img': image, 'label':label }\n",
    "    \n",
    "        if self.phase == 'val':\n",
    "            file = self.val_images[index]\n",
    "            path = os.path.join(opt.dataroot,file)\n",
    "            image = Image.open(path)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                image = self.transform['val'](image)\n",
    "                \n",
    "            for key in self.val_labels.keys():\n",
    "                if file in key:\n",
    "                    label= self.val_labels[key]\n",
    "                    break\n",
    "        \n",
    "            label = torch.LongTensor([label])\n",
    "    #         label = torch.FloatTensor([label])\n",
    "            return {'img': image, 'label':label }\n",
    "    \n",
    "        if self.phase == 'test':\n",
    "            file = self.test_images[index]\n",
    "            path = os.path.join(opt.dataroot,file)\n",
    "            image = Image.open(path)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                image = self.transform['val'](image)\n",
    "                \n",
    "            for key in self.test_labels.keys():\n",
    "                if file in key:\n",
    "                    label= self.test_labels[key]\n",
    "                    break\n",
    "        \n",
    "            label = torch.LongTensor([label])\n",
    "    #         label = torch.FloatTensor([label])\n",
    "            return {'img': image, 'label':label }\n",
    "\n",
    "\n",
    "    \n",
    "opt.phase='train'\n",
    "image_dataset=Data(transform,opt.phase)\n",
    "    \n",
    "train_loader = data.DataLoader(image_dataset,batch_size=opt.train_batch_size,num_workers=opt.num_threads,shuffle=True,pin_memory= False)\n",
    "print(f'{len(image_dataset)} images loaded under train')\n",
    "\n",
    "opt.phase='val'\n",
    "val_dataset=Data(transform,opt.phase)                        \n",
    "val_loader = data.DataLoader(val_dataset,batch_size=opt.val_batch_size,num_workers=opt.num_threads,shuffle=True,pin_memory= False)\n",
    "print(f'{len(val_dataset)} images loaded under Validation')\n",
    "\n",
    "opt.phase='test'\n",
    "test_dataset=Data(transform,opt.phase)                        \n",
    "test_loader = data.DataLoader(test_dataset,batch_size=opt.test_batch_size,num_workers=opt.num_threads,shuffle=False,pin_memory= False)\n",
    "print(f'{len(test_dataset)} images loaded under test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = 0.\n",
    "# std = 0.\n",
    "# nb_samples = 0.\n",
    "# for data_ in tqdm(train_loader):\n",
    "#     images = data_['img']\n",
    "#     batch_samples = images.size(0)\n",
    "#     images = images.view(batch_samples, images.size(1), -1)\n",
    "    \n",
    "#     mean += images.mean(2).sum(0)\n",
    "#     std += images.std(2).sum(0)\n",
    "#     nb_samples += batch_samples\n",
    "\n",
    "# mean /= nb_samples\n",
    "# std /= nb_samples\n",
    "# print(mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_val = 0.\n",
    "# std_val = 0.\n",
    "# nb_samples = 0.\n",
    "# for data_ in tqdm(val_loader):\n",
    "#     images = data_['img']\n",
    "#     batch_samples = images.size(0)\n",
    "#     images = images.view(batch_samples, images.size(1), -1)\n",
    "    \n",
    "#     mean_val += images.mean(2).sum(0)\n",
    "#     std_val += images.std(2).sum(0)\n",
    "#     nb_samples += batch_samples\n",
    "\n",
    "# mean_val /= nb_samples\n",
    "# std_val /= nb_samples\n",
    "# print(mean_val,std_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_test = 0.\n",
    "# std_test = 0.\n",
    "# nb_samples = 0.\n",
    "# for data_ in tqdm(test_loader):\n",
    "#     images = data_['img']\n",
    "#     batch_samples = images.size(0)\n",
    "#     images = images.view(batch_samples, images.size(1), -1)\n",
    "    \n",
    "#     mean_test += images.mean(2).sum(0)\n",
    "#     std_test += images.std(2).sum(0)\n",
    "#     nb_samples += batch_samples\n",
    "\n",
    "# mean_test /= nb_samples\n",
    "# std_test /= nb_samples\n",
    "# print(mean_test,std_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_pooling():\n",
    "    return nn.MaxPool2d(2)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_z=512      # number of dimensions in latent space.\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(64),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv11 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(64),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        \n",
    "        self.conv2=nn.Sequential(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(128),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv22=nn.Sequential(nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(128),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv3=nn.Sequential(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(256),\n",
    "                                 nn.LeakyReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv33=nn.Sequential(nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(256),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv4=nn.Sequential(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(512),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv44=nn.Sequential(nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(512),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )        \n",
    "        self.conv5=nn.Sequential(nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(1024),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.conv55=nn.Sequential(nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3,stride=1,padding=1),\n",
    "                                 nn.BatchNorm2d(1024),\n",
    "                                 nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.down_pooling = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.mu = nn.Linear(1024*14*14, 256)\n",
    "        self.logvar = nn.Linear(1024*14*14, 256)\n",
    "\n",
    "        \n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*log_var) # standard deviation\n",
    "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std) # sampling as if coming from the input space\n",
    "        return sample\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x=self.conv1(x)\n",
    "        x=self.conv11(x)\n",
    "        x = self.down_pooling(x)\n",
    "        \n",
    "        x=self.conv2(x)\n",
    "        x=self.conv22(x)\n",
    "        x = self.down_pooling(x)\n",
    "        \n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        x=self.conv33(x)\n",
    "        x = self.down_pooling(x)\n",
    "\n",
    "        \n",
    "        x=self.conv4(x)\n",
    "        x=self.conv44(x)\n",
    "        x = self.down_pooling(x)\n",
    "        \n",
    "        x=self.conv5(x)\n",
    "        x=self.conv55(x)\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "        mu, logvar = self.mu(x), self.logvar(x)\n",
    "        x = self.reparameterize(mu, logvar)\n",
    "        \n",
    "        return x,mu,logvar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_pooling(in_channels, out_channels, kernel_size=2, stride=2):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "def conv_bn_leru(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "    return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(256,1024*14*14),\n",
    "                                nn.ReLU()\n",
    "                                )\n",
    "        self.up_pool6 = up_pooling(1024, 1024)\n",
    "        self.conv6 = conv_bn_leru(1024, 512)\n",
    "        self.up_pool7 = up_pooling(512, 512)\n",
    "        self.conv7 = conv_bn_leru(512, 256)\n",
    "        self.up_pool8 = up_pooling(256, 256)\n",
    "        self.conv8 = conv_bn_leru(256, 128)\n",
    "        self.up_pool9 = up_pooling(128, 128)\n",
    "        self.conv9 = conv_bn_leru(128, 64)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(64, 1,1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x  = self.fc(x)\n",
    "        x5 = x.view(x.size(0),1024,14,14)\n",
    "        \n",
    "        p6 = self.up_pool6(x5)\n",
    "        x6 = self.conv6(p6)\n",
    "\n",
    "        p7 = self.up_pool7(x6)\n",
    "        x7 = self.conv7(p7)\n",
    "\n",
    "        p8 = self.up_pool8(x7)\n",
    "        x8 = self.conv8(p8)\n",
    "\n",
    "        p9 = self.up_pool9(x8)\n",
    "        x9 = self.conv9(p9)\n",
    "        \n",
    "        output = self.conv10(x9)\n",
    "        output = self.relu(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sobel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Sobel, self).__init__()\n",
    "        self.x_filter = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]])\n",
    "        self.y_filter = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "        self.convx = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.convy = nn.Conv2d(1, 1, kernel_size=3 , stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.weights_x = torch.from_numpy(self.x_filter).float().unsqueeze(0).unsqueeze(0)\n",
    "        self.weights_y = torch.from_numpy(self.y_filter).float().unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        self.convx.weight = nn.Parameter(self.weights_x)\n",
    "        self.convy.weight = nn.Parameter(self.weights_y)\n",
    "        \n",
    "    def forward(self,x,target):\n",
    "        g1_x = self.convx(x)\n",
    "        g2_x = self.convx(target)\n",
    "        g1_y = self.convy(x)\n",
    "        g2_y = self.convy(target)\n",
    "        \n",
    "        g_1 = torch.pow(g1_x, 2) + torch.pow(g1_y, 2)\n",
    "        g_2 = torch.pow(g2_x, 2) + torch.pow(g2_y, 2)\n",
    "        \n",
    "        loss=torch.mean((g_1 - g_2).pow(2))\n",
    "        \n",
    "        return loss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weight_init(m):\n",
    "#     if isinstance(m, nn.Conv2d):\n",
    "#         init.xavier_normal_(m.weight)\n",
    "#         init.constant_(m.bias, 0)\n",
    "#     if isinstance(m, nn.Linear):\n",
    "#         init.xavier_normal_(m.weight)\n",
    "#         init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_params(module: nn.Module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "def frozen_params(module: nn.Module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=Encoder()\n",
    "encoder.apply(weight_init)\n",
    "decoder=Decoder()\n",
    "decoder.apply(weight_init)\n",
    "encoder, decoder= encoder.to(device), decoder.to(device)\n",
    "\n",
    "sobel=Sobel()\n",
    "sobel=sobel.to(device)\n",
    "frozen_params(sobel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSIM_Loss(SSIM):\n",
    "    def forward(self, img1, img2):\n",
    "        return ( 1 - super(SSIM_Loss, self).forward(img1, img2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(**kwargs):\n",
    "    torch.cuda.empty_cache()\n",
    "    opt = Config()\n",
    "    print('loading the model...')\n",
    "    sobel.eval()\n",
    "    enc_optim = torch.optim.Adam(encoder.parameters(), lr = opt.lr,amsgrad=True)\n",
    "    dec_optim = torch.optim.Adam(decoder.parameters(), lr = opt.lr,amsgrad=True)\n",
    "#     enc_scheduler = torch.optim.lr_scheduler.StepLR(enc_optim, step_size=50, gamma=0.1)\n",
    "#     dec_scheduler = torch.optim.lr_scheduler.StepLR(dec_optim, step_size=50, gamma=0.1)\n",
    "    enc_scheduler = lr_scheduler.CosineAnnealingLR(enc_optim, T_max=10, eta_min=0.000001)\n",
    "    dec_scheduler = lr_scheduler.CosineAnnealingLR(enc_optim, T_max=10, eta_min=0.000001)\n",
    "#     criterion = SSIM_Loss(data_range=1.0, size_average=True, channel=1)\n",
    "    criterion = nn.MSELoss()\n",
    "    l1_loss = nn.L1Loss()\n",
    "    try:\n",
    "        state = torch.load(os.path.join(opt.model_path, 'model.pth'))\n",
    "        encoder.load_state_dict(state['enc_state_dict'])\n",
    "        decoder.load_state_dict(state['dec_state_dict'])\n",
    "        print(\"Loaded pre-trained models with success.\")\n",
    "        e_counter=state['epoch']\n",
    "        best_valid_loss = state['valid_loss_min']\n",
    "#         best_valid_loss = float('inf')\n",
    "        prev_loss=float('inf')\n",
    "        print('Previously Trained for {} epoches'.format(e_counter))\n",
    "        e_counter+=1\n",
    "    except FileNotFoundError:\n",
    "        print(\"Pre-trained weights not found. Training from scratch.\")\n",
    "        e_counter=0\n",
    "        best_valid_loss = float('inf')\n",
    "        prev_loss=float('inf')\n",
    "    elrs = []\n",
    "    dlrs = []\n",
    "    t_loss = []\n",
    "    v_loss=[]\n",
    "    epoches=[]\n",
    "    for epoch in range(e_counter,opt.max_epochs):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        epoch_start_time = time.time()\n",
    "        print()\n",
    "        print('==================================================================')\n",
    "        print('-------------Epoch: {}/{}------------'.format(epoch,opt.max_epochs))\n",
    "        kl_annealtime = 100\n",
    "        p= 100\n",
    "        l= 10\n",
    "        s= 10\n",
    "        e_loss=e_vloss=0.0\n",
    "        e_rl=e_kl=e_sl=0.0\n",
    "        e_vrl=e_vkl=e_vsl=0.0\n",
    "        for idx,batch in enumerate(train_loader,1):\n",
    "            image=batch['img']\n",
    "            image=image.to(device)\n",
    "            encoder.zero_grad()\n",
    "            decoder.zero_grad()\n",
    "            \n",
    "            bs, n_crops, c, h, w = images.size()\n",
    "            inputs = images.view(-1, c, h, w)\n",
    "            inputs = torch.autograd.Variable(inputs.view(-1, c, h, w))    \n",
    "            enc_out,mu,logvar = encoder(inputs).view(bs, n_crops, -1).mean(dim=1)\n",
    "            \n",
    "            dec_out = decoder(enc_out)    \n",
    "            rl  = p*criterion(dec_out, image)+ l*l1_loss (image,dec_out)\n",
    "            KLD = torch.mean(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()))\n",
    "            kl_weight = (1./kl_annealtime)\n",
    "            kl  = kl_weight*KLD\n",
    "            sl  = s*sobel(dec_out,image)\n",
    "            loss=rl+kl+sl\n",
    "            loss.backward() \n",
    "            enc_optim.step()\n",
    "            dec_optim.step()\n",
    "            e_loss+=loss.item()\n",
    "            e_rl +=rl.item()\n",
    "            e_kl +=kl.item()\n",
    "            e_sl +=sl.item()\n",
    "            if idx%1000 == 0:\n",
    "                print(idx,'/',len(train_loader),'|Loss: %.3f | RL: %.3f | KL: %.3f | sobel: %.3f ' %(e_loss/idx,e_rl/idx,e_kl/idx,e_sl/idx))\n",
    "        mean_loss = e_loss/len(train_loader)\n",
    "        print('Train Loss: %.3f'%(mean_loss))\n",
    "        t_loss.append(mean_loss)\n",
    "        with open(f'{opt.save_path}/train_logs.txt', 'a') as file:\n",
    "            file.write('epoch: ' + str(epoch) + ',loss: '+ str(mean_loss) + ',rl: ' + str(e_rl) + ',kl: ' + str(e_kl) + ',sl: ' + str(e_sl) +'\\n')  \n",
    "        state = {\n",
    "                'epoch': epoch,\n",
    "                'loss_min': mean_loss,\n",
    "                'enc_state_dict': encoder.state_dict(),\n",
    "                'dec_state_dict': decoder.state_dict(),\n",
    "                }\n",
    "        if epoch % opt.plot_every == 0:\n",
    "            if mean_loss < prev_loss:\n",
    "                torch.save(state, os.path.join(opt.model_path, 'train_model.pth'))\n",
    "                filename = 'decoded_%04d.png' % (epoch)\n",
    "                decoded_path = os.path.join(opt.decode_path, filename)\n",
    "                tv.utils.save_image(dec_out.cpu().data, decoded_path)\n",
    "                prev_loss = mean_loss\n",
    "        print()    \n",
    "        print('...........................validation....................................') \n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, batch in enumerate(val_loader,1):\n",
    "                image,label=batch['img'],batch['label']\n",
    "                image, label = image.to(device),label.to(device)\n",
    "                \n",
    "                enc_out,mu,logvar = encoder(image)\n",
    "                dec_out = decoder(enc_out)\n",
    "\n",
    "                rl  = p*criterion(dec_out, image)+ l*l1_loss (image,dec_out)\n",
    "                KLD = torch.mean(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()))\n",
    "                kl_weight = (1./kl_annealtime)\n",
    "                kl  = kl_weight*KLD\n",
    "                sl  = s*sobel(dec_out,image)\n",
    "\n",
    "                eval_loss = rl+kl+sl\n",
    "                e_vloss += eval_loss.item()\n",
    "                e_vrl +=rl\n",
    "                e_vkl +=kl\n",
    "                e_vsl +=sl\n",
    "               \n",
    "                \n",
    "                if idx%400 == 0:\n",
    "#                     print('VAL_Batch ',i,'/',len(val_loader), '|| Loss: %.5f'%(eval_loss/(i+1)))\n",
    "                    print(idx,'/',len(val_loader),'|Loss: %.3f | RL: %.3f | KL: %.3f | sobel: %.3f ' %(e_vloss/idx,e_vrl/idx,e_vkl/idx,e_vsl/idx))\n",
    "\n",
    "\n",
    "        \n",
    "        valid_loss = e_vloss/len(val_loader)\n",
    "        print('Valid Loss: %.3f'%(valid_loss))\n",
    "        v_loss.append(valid_loss)\n",
    "        epoches.append(epoch)\n",
    "        \n",
    "        state = {\n",
    "                'epoch': epoch,\n",
    "                'valid_loss_min': valid_loss,\n",
    "                'enc_state_dict': encoder.state_dict(),\n",
    "                'dec_state_dict': decoder.state_dict(),\n",
    "                'enc_optimizer': enc_optim.state_dict(),\n",
    "                'dec_optimizer': dec_optim.state_dict(),\n",
    "                }\n",
    "        \n",
    "        if epoch % opt.save_every == 0 or epoch == opt.max_epochs - 1:\n",
    "            if valid_loss < best_valid_loss:\n",
    "                print('Validation loss decreased ({:.5f} --> {:.5f}). Saving model ...'.format(best_valid_loss,valid_loss))\n",
    "                torch.save(state, os.path.join(opt.model_path, 'model.pth'))\n",
    "                filename = 'fake_%04d.png' %(epoch)\n",
    "                val_path = os.path.join(opt.val_path, filename)\n",
    "                tv.utils.save_image(dec_out.cpu().data, val_path)\n",
    "                with open(f'{opt.save_path}/val_logs.txt', 'a') as file:\n",
    "                    file.write('epoch: ' + str(epoch) + ',loss: '+ str(valid_loss) + ',rl: ' + str(e_vrl) + ',kl: ' + str(e_vkl) + ',sl: ' + str(e_vsl) +'\\n')\n",
    "\n",
    "                best_valid_loss = valid_loss\n",
    "                \n",
    "        epoch_time = int(time.time() - epoch_start_time)\n",
    "        print(f'-----------------Epoch cost time {epoch_time}s--------------------')\n",
    "        elrs.append(enc_optim.param_groups[0][\"lr\"])\n",
    "        dlrs.append(dec_optim.param_groups[0][\"lr\"])\n",
    "        print('Enc_learning_rate :',enc_scheduler.get_lr())\n",
    "        print('Dec_learning_rate :',dec_scheduler.get_lr())\n",
    "        \n",
    "        enc_scheduler.step()\n",
    "        dec_scheduler.step()       \n",
    "    \n",
    "    plt.plot(elrs)\n",
    "    filepath=os.path.join(opt.save_path, 'ELR.png')\n",
    "    plt.savefig(filepath)\n",
    "    plt.plot(dlrs)\n",
    "    filepath=os.path.join(opt.save_path, 'DLR.png')\n",
    "    plt.savefig(filepath)\n",
    "    \n",
    "    filepath=os.path.join(opt.save_path, 'losses.png')\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(epoches, t_loss, label=\"Train\")\n",
    "    plt.plot(epoches, v_loss, label=\"Validation\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(filepath)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loading the model...')\n",
    "encoder=Encoder()\n",
    "decoder=Decoder()\n",
    "encoder, decoder= encoder.to(device), decoder.to(device)\n",
    "\n",
    "sobel=Sobel().to(device)\n",
    "state = torch.load(os.path.join(opt.model_path, 'train_model.pth'))\n",
    "encoder.load_state_dict(state['enc_state_dict'])\n",
    "decoder.load_state_dict(state['dec_state_dict'])\n",
    "\n",
    "print(\"Loaded pre-trained regressor with success.\")\n",
    "e_counter=state['epoch']\n",
    "print('Previously Trained for {} epoches'.format(e_counter))\n",
    "\n",
    "criterion = SSIM_Loss(data_range=1.0, size_average=True, channel=1)\n",
    "l1_loss = nn.L1Loss()\n",
    "kl_annealtime = 200\n",
    "p_s = 100000\n",
    "val_epoch_loss=0.0\n",
    "i=0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        image,label=batch['img'],batch['label']\n",
    "        image, label = image.to(device),label.to(device)\n",
    "\n",
    "        enc_out,mu,logvar = encoder(image)\n",
    "            \n",
    "        dec_out = decoder(enc_out)\n",
    "\n",
    "        \n",
    "        rl  = p_s*criterion(dec_out, image)\n",
    "        l1  = 1000*l1_loss (image,dec_out) \n",
    "        KLD = torch.mean(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()))\n",
    "        kl_weight = (1./kl_annealtime)\n",
    "        kl = kl_weight*KLD\n",
    "        sobel_loss = sobel(dec_out,image)\n",
    "        sobel_loss = 1000*sobel_loss\n",
    "        \n",
    "        eval_loss=rl+l1+kl+sobel_loss\n",
    "        val_epoch_loss += eval_loss.item()\n",
    "        \n",
    "        \n",
    "        filename1 = 'fake_%02d.png' %(i)\n",
    "        filename2 = 'orig_%02d.png' %(0)\n",
    "        val_path1 = os.path.join(opt.test_path, filename1)\n",
    "        val_path2 = os.path.join(opt.test_path, filename2)\n",
    "        tv.utils.save_image(dec_out.cpu().data, val_path1)\n",
    "        tv.utils.save_image(image.cpu().data, val_path2)\n",
    "        i+=1\n",
    "        if i ==11:\n",
    "            break\n",
    "valid_loss = val_epoch_loss/len(test_loader)\n",
    "print('test Loss: %.5f'%(valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
